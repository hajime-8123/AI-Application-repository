{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8e8hOkCgbwY0iIK+DAK02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hajime-8123/AI-Application-repository/blob/main/Week5_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QNbEANKnBlRy"
      },
      "outputs": [],
      "source": [
        "# Import TensorFlow and other Liblaries\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Split the dataset into trainning and test sets\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79FS8PkcEkfM",
        "outputId": "1bac62e1-9547-45a6-a4ca-03fbdc14fa33"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Explore the dataset\n",
        "\n",
        "#Plot the first 5 images from the training set\n",
        "plt.figure(figsize=(10,2))\n",
        "for i in range(5):\n",
        "    plt.subplot(1,5, i+1)\n",
        "    plt.imshow(train_images[i], cmap='gray')\n",
        "    plt.title(f\"Label: {train_labels[i]}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "Wr-S-wraEruK",
        "outputId": "d28d4e25-54d4-4aa1-8b8c-b5909b0dda02"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAADHCAYAAADLacZgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApf0lEQVR4nO3deXhV1b3G8TdMCUOGMiWghKFg0cqgCAFEQIlSFRQBQasi1SteSRBRqBcuArdVQRBFEJUHK4PaMklAsbVymbxQCDLZS5E0IggIRBAzMCVC1v2DS+rJ2iQnyTnZZyffz/PsP9Yv65zzy+Flh8XJXjvMGGMEAAAAAB5Wxe0GAAAAAKCsWNgAAAAA8DwWNgAAAAA8j4UNAAAAAM9jYQMAAADA81jYAAAAAPA8FjYAAAAAPI+FDQAAAADPY2EDAAAAwPNY2JSjAwcOKCwsTC+//HLAnnP9+vUKCwvT+vXrA/acqJjIH9xGBuEm8gc3kb/ywcKmGPPnz1dYWJi2bdvmditBMWnSJIWFhVlHRESE261BFT9/kvTtt99q0KBBiomJUVRUlO6++259/fXXbreF/1cZMvhTt956q8LCwpScnOx2K1DFz19aWppGjRqlrl27KiIiQmFhYTpw4IDbbeH/VfT8SdKiRYt0/fXXKyIiQg0aNNCjjz6qEydOuN1WqVVzuwGEhjfffFN16tQpGFetWtXFblBZnDp1SjfffLOysrI0btw4Va9eXa+++qp69OihXbt2qV69em63iEpk+fLl2rx5s9ttoBLZvHmzZs6cqWuuuUZXX321du3a5XZLqETefPNNDR8+XL169dIrr7yiw4cP67XXXtO2bduUmprqyf/kZmEDSdLAgQNVv359t9tAJfPGG28oPT1dW7duVceOHSVJt99+u6699lpNnz5dL774ossdorI4d+6cnnnmGT377LOaMGGC2+2gkrjrrruUmZmpyMhIvfzyyyxsUG7y8vI0btw4de/eXatXr1ZYWJgkqWvXrurbt6/mzp2rESNGuNxlyfGraAGQl5enCRMmqEOHDoqOjlbt2rV10003ad26dZd9zKuvvqqmTZuqZs2a6tGjh3bv3m3N2bt3rwYOHKi6desqIiJCN9xwgz788MNi+zlz5oz27t1boo8SjTHKzs6WMcbvxyA0eDl/y5YtU8eOHQsWNZLUunVr9erVS0uWLCn28QgNXs7gJVOnTlV+fr5Gjx7t92MQGrycv7p16yoyMrLYeQhdXs3f7t27lZmZqcGDBxcsaiSpT58+qlOnjhYtWlTsa4UiFjYBkJ2drbfffls9e/bUSy+9pEmTJun48ePq3bu34/++LFy4UDNnzlRSUpLGjh2r3bt365ZbblFGRkbBnH/84x/q3LmzvvzyS/3Hf/yHpk+frtq1a6tfv35KSUkpsp+tW7fq6quv1uuvv+7399CiRQtFR0crMjJSDz74oE8vCG1ezV9+fr7+/ve/64YbbrC+1qlTJ+3bt085OTn+vQlwlVczeMnBgwc1ZcoUvfTSS6pZs2aJvne4z+v5g7d5NX+5ubmS5HjOq1mzpnbu3Kn8/Hw/3oEQY1CkefPmGUnm888/v+yc8+fPm9zcXJ/aDz/8YGJjY80jjzxSUNu/f7+RZGrWrGkOHz5cUE9NTTWSzKhRowpqvXr1Mm3atDHnzp0rqOXn55uuXbuaVq1aFdTWrVtnJJl169ZZtYkTJxb7/c2YMcMkJyeb999/3yxbtsyMHDnSVKtWzbRq1cpkZWUV+3gEV0XO3/Hjx40k87vf/c762uzZs40ks3fv3iKfA8FXkTN4ycCBA03Xrl0LxpJMUlKSX49FcFWG/F0ybdo0I8ns37+/RI9D8FTk/B0/ftyEhYWZRx991Ke+d+9eI8lIMidOnCjyOUIRn9gEQNWqVVWjRg1JF/8X+uTJkzp//rxuuOEG7dixw5rfr18/XXHFFQXjTp06KSEhQX/+858lSSdPntTatWs1aNAg5eTk6MSJEzpx4oS+//579e7dW+np6fr2228v20/Pnj1ljNGkSZOK7X3kyJGaNWuWfv3rX2vAgAGaMWOGFixYoPT0dL3xxhslfCfgBq/m7+zZs5Kk8PBw62uXLli8NAehzasZlKR169bpgw8+0IwZM0r2TSNkeDl/8D6v5q9+/foaNGiQFixYoOnTp+vrr7/W//zP/2jw4MGqXr26JG/+DGZhEyALFixQ27ZtFRERoXr16qlBgwb6+OOPlZWVZc1t1aqVVbvqqqsKtnj86quvZIzRc889pwYNGvgcEydOlCR99913Qftefv3rXysuLk7//d//HbTXQGB5MX+XPv6+9HH4T507d85nDkKfFzN4/vx5Pfnkk3rooYd8rvOC93gxf6g4vJq/OXPm6I477tDo0aP185//XN27d1ebNm3Ut29fSfLZLdcr2BUtAN577z0NHTpU/fr105gxY9SwYUNVrVpVkydP1r59+0r8fJd+p3H06NHq3bu345yWLVuWqefiNGnSRCdPngzqayAwvJq/unXrKjw8XEePHrW+dqnWuHHjMr8Ogs+rGVy4cKHS0tI0Z84c694hOTk5OnDggBo2bKhatWqV+bUQPF7NHyoGL+cvOjpaK1eu1MGDB3XgwAE1bdpUTZs2VdeuXdWgQQPFxMQE5HXKEwubAFi2bJlatGih5cuX++wscWllXVh6erpV++c//6lmzZpJunghvyRVr15diYmJgW+4GMYYHThwQNddd125vzZKzqv5q1Klitq0aeN447PU1FS1aNGC3YI8wqsZPHjwoH788UfdeOON1tcWLlyohQsXKiUlRf369QtaDyg7r+YPFUNFyF98fLzi4+MlSZmZmdq+fbsGDBhQLq8daPwqWgBcupml+clWyampqZe90duKFSt8fj9y69atSk1N1e233y5JatiwoXr27Kk5c+Y4/m/28ePHi+ynJFtNOj3Xm2++qePHj+tXv/pVsY+H+7ycv4EDB+rzzz/3WdykpaVp7dq1uvfee4t9PEKDVzN43333KSUlxTok6Y477lBKSooSEhKKfA64z6v5Q8VQ0fI3duxYnT9/XqNGjSrV493GJzZ+euedd/TJJ59Y9ZEjR6pPnz5avny57rnnHt15553av3+/3nrrLV1zzTU6deqU9ZiWLVuqW7dueuKJJ5Sbm6sZM2aoXr16+u1vf1swZ/bs2erWrZvatGmjxx57TC1atFBGRoY2b96sw4cP64svvrhsr1u3btXNN9+siRMnFnvxWNOmTTV48GC1adNGERER2rhxoxYtWqT27dvr8ccf9/8NQlBV1PwNHz5cc+fO1Z133qnRo0erevXqeuWVVxQbG6tnnnnG/zcIQVcRM9i6dWu1bt3a8WvNmzfnk5oQUhHzJ0lZWVmaNWuWJGnTpk2SpNdff10xMTGKiYlRcnKyP28Pgqyi5m/KlCnavXu3EhISVK1aNa1YsUKffvqpnn/+ee9ed1j+G7F5y6Wt/i53HDp0yOTn55sXX3zRNG3a1ISHh5vrrrvOrFq1yjz88MOmadOmBc91aau/adOmmenTp5smTZqY8PBwc9NNN5kvvvjCeu19+/aZIUOGmLi4OFO9enVzxRVXmD59+phly5YVzCnrVpP/9m//Zq655hoTGRlpqlevblq2bGmeffZZk52dXZa3DQFS0fNnjDGHDh0yAwcONFFRUaZOnTqmT58+Jj09vbRvGQKsMmSwMLHdc8io6Pm71JPT8dPe4Y6Knr9Vq1aZTp06mcjISFOrVi3TuXNns2TJkrK8Za4LM4ZbzQMAAADwNq6xAQAAAOB5LGwAAAAAeB4LGwAAAACex8IGAAAAgOexsAEAAADgeUFb2MyePVvNmjVTRESEEhIStHXr1mC9FGAhf3AT+YPbyCDcRP7glqBs97x48WINGTJEb731lhISEjRjxgwtXbpUaWlpatiwYZGPzc/P15EjRxQZGamwsLBAtwaPMsYoJydHjRs3VpUqRa/Hy5I/iQzCRv7gtvLKIPmDE86BcFNJ8heUG3R26tTJ5+ZmFy5cMI0bNzaTJ08u9rGHDh0q8mZIHJX7OHToUFDzRwY5ijrIH4fbR7AzSP44ijo4B3K4efiTv4D/KlpeXp62b9+uxMTEglqVKlWUmJiozZs3W/Nzc3OVnZ1dcBjuF4oiREZGFvn1kuZPIoPwH/mD2wKdQfKHkuAcCDcVlz8pCNfYnDhxQhcuXFBsbKxPPTY2VseOHbPmT548WdHR0QVHfHx8oFtCBVLcx9IlzZ9EBuE/8ge3BTqD5A8lwTkQbvLnVxNd3xVt7NixysrKKjgOHTrkdkuoZMgg3ET+4CbyB7eRQQRStUA/Yf369VW1alVlZGT41DMyMhQXF2fNDw8PV3h4eKDbQCVV0vxJZBCBQ/7gNn4Gw02cA+G2gH9iU6NGDXXo0EFr1qwpqOXn52vNmjXq0qVLoF8O8EH+4CbyB7eRQbiJ/MF1fm1RUUKLFi0y4eHhZv78+WbPnj1m2LBhJiYmxhw7dqzYx2ZlZbm+6wJH6B5ZWVlBzR8Z5CjqIH8cbh/BziD54yjq4BzI4ebhT/6CsrAxxphZs2aZ+Ph4U6NGDdOpUyezZcsWvx5HoDmKOvwJdVnyRwY5ijrIH4fbR7AzSP44ijo4B3K4efiTv6DcoLMssrOzFR0d7XYbCFFZWVmKiooK6muQQVwO+YPbgp1B8oeicA6Em/zJn+u7ogEAAABAWbGwAQAAAOB5LGwAAAAAeB4LGwAAAACex8IGAAAAgOexsAEAAADgeSxsAAAAAHgeCxsAAAAAnsfCBgAAAIDnVXO7AQDe06FDB6uWnJzsMx4yZIg1Z+HChVZt1qxZVm3Hjh1l6A4AAFRGfGIDAAAAwPNY2AAAAADwPBY2AAAAADyPhQ0AAAAAz2PzAJdUrVrVqkVHR5f6+QpfuF2rVi1rzi9+8QurlpSUZNVefvlln/H9999vzTl37pxVmzJlilX7r//6L7tZeEr79u2t2urVq61aVFSUz9gYY8156KGHrNpdd91l1erVq1eCDoHA6tWrl8/4/ffft+b06NHDqqWlpQWtJ3jf+PHjrZrTz8gqVXz/z7lnz57WnA0bNgSsL6Ai4RMbAAAAAJ7HwgYAAACA57GwAQAAAOB5LGwAAAAAeB6bB5RAfHy8VatRo4ZV69q1q1Xr1q2bzzgmJsaaM2DAgNI354fDhw9btZkzZ1q1e+65x2eck5Njzfniiy+sGhczel+nTp2s2gcffGDVnDa6KLxZgFNu8vLyrJrTRgGdO3f2Ge/YscOv54Kte/fuVs3pPU9JSSmPdjyhY8eOPuPPP//cpU7gVUOHDrVqzz77rFXLz88v9rmcNmIB4IxPbAAAAAB4HgsbAAAAAJ7HwgYAAACA53GNzWU43ZRw7dq1Vq0sN9UMJqff23W6OdipU6esWuGb0R09etSa88MPP1g1bk4X2grftPX666+35rz33ntWrVGjRqV6vfT0dKs2depUq7Zo0SKrtmnTJp+xU3YnT55cqr4qG6eb+7Vq1cqqVdZrbArfDFGSmjdv7jNu2rSpNScsLCxoPcH7nDITERHhQicIVQkJCVbtwQcftGpONwP+5S9/Wezzjx492qodOXLEqhW+Blyy/y2Qmppa7OuFCj6xAQAAAOB5LGwAAAAAeB4LGwAAAACex8IGAAAAgOexecBlHDx40Kp9//33Vi3Ymwc4XbCVmZlp1W6++WafsdPNC999992A9QXvmTNnjs/4/vvvD+rrOW1OUKdOHavmdGPXwhe8t23bNmB9VTZDhgyxaps3b3ahk9DktDnGY4895jN22lRj7969QesJ3pOYmOgzHjFihF+Pc8pRnz59fMYZGRmlbwwhY/DgwT7j1157zZpTv359q+a0Ucn69eutWoMGDXzG06ZN86svp+cv/Fz33XefX88VCvjEBgAAAIDnsbABAAAA4HksbAAAAAB4HgsbAAAAAJ7H5gGXcfLkSas2ZswYq1b4Ij9J2rlzp1WbOXNmsa+5a9cuq3brrbdatdOnT1u1wnehHTlyZLGvh4qrQ4cOVu3OO+/0Gft753Sni/s/+ugjq/byyy/7jJ3ucOz0d+OHH36warfccovPmLu8l16VKvz/VVHefvvtYuekp6eXQyfwCqc7tc+bN89n7O/GQk4XeH/zzTelawyuqFbN/qf0DTfcYNXmzp3rM65Vq5Y157PPPrNqv//9763axo0brVp4eLjPeMmSJdac2267zao52bZtm1/zQhE/8QAAAAB4HgsbAAAAAJ7HwgYAAACA55V4YfPZZ5+pb9++aty4scLCwrRixQqfrxtjNGHCBDVq1Eg1a9ZUYmIiv5+MgNm0aRP5g2vIH9xGBuEm8odQV+LNA06fPq127drpkUceUf/+/a2vT506VTNnztSCBQvUvHlzPffcc+rdu7f27NmjiIiIgDTtlsJ/gSVp7dq1Vi0nJ8eqtWvXzmf86KOPWnMKX3wtOW8U4OQf//iHz3jYsGF+Pc5rzpw5U2nzdznt27e3aqtXr7ZqUVFRPmNjjDXnL3/5i1W7//77rVqPHj2s2vjx433GThdlHz9+3Kp98cUXVi0/P99nXHjjA0m6/vrrrdqOHTusWiCFev7atm1r1WJjY4P+ul7mz0XeTn+f3BLqGawMHn74YavWuHHjYh/ndLf4hQsXBqKlckP+bA8++KBV82dTEqfzyuDBg61adna2X30Ufqy/GwUcPnzYqi1YsMCvx4aiEi9sbr/9dt1+++2OXzPGaMaMGRo/frzuvvtuSRf/0sbGxmrFihW67777ytYtKr1bb71VAwYMcPwa+UOwkT+4jQzCTeQPoS6g19js379fx44dU2JiYkEtOjpaCQkJ2rx5s+NjcnNzlZ2d7XMApVGa/ElkEIFB/uA2fgbDTZwDEQoCurA5duyYJPtXH2JjYwu+VtjkyZMVHR1dcDRp0iSQLaESKU3+JDKIwCB/cBs/g+EmzoEIBa7vijZ27FhlZWUVHIcOHXK7JVQyZBBuIn9wE/mD28ggAqnE19gUJS4uTpKUkZGhRo0aFdQzMjIcL3CWLt4ptfDdUr3E349Ms7Kyip3z2GOPWbXFixdbtcIXVuOi0uRP8lYGr7rqKqs2ZswYq+Z0QfSJEyd8xkePHrXmOF0weOrUKav28ccf+1ULlJo1a1q1Z555xqo98MADQeuhOKGQvzvuuMOqOb13lZXTRgrNmzcv9nHffvttMNoJuMr4MzjY6tevb9UeeeQRq1b453JmZqY15/nnnw9YX6EoFM6Bwfb73//eqo0bN86qOW3O88Ybb/iMC2+4I/n/b0on//mf/1mqxz355JNWzWmjH68I6Cc2zZs3V1xcnNasWVNQy87OVmpqqrp06RLIlwIs5A9uIn9wGxmEm8gfQkGJP7E5deqUvvrqq4Lx/v37tWvXLtWtW1fx8fF66qmn9Pzzz6tVq1YFW/01btxY/fr1C2TfqKROnTqlr7/+umBM/lCeyB/cRgbhJvKHUFfihc22bdt08803F4yffvppSRf3dZ8/f75++9vf6vTp0xo2bJgyMzPVrVs3ffLJJxV2/3KUr507d6pPnz4FY/KH8kT+4DYyCDeRP4S6MOP0i4Auys7O9uuGaV5Tu3Ztn/FHH31kzXG66aHTPYM+/fTTwDXmMVlZWdaNJgMtVDLo9DvHS5cutWpO11U4XRdT+OZd27Zts+Y4XY/hdPOuYLtw4YLP2Ok05bR96E033RS0nqTQz9+8efOsmtPNBJ1+J3zKlCmlek0veffdd62a03VZ//znP33GnTt3tuY4XUNRHoKdwVA5/7mhWbNmVu2DDz6wak7XixS+xsbpWozf/e53pe4tVIT6OTCQJkyYYNUmTpxo1fLy8qzaX//6V6tW+GbXZ8+e9asPp0Wh0803//SnPxX7OKfrvJy+p1DlT/5c3xUNAAAAAMqKhQ0AAAAAz2NhAwAAAMDzWNgAAAAA8LyA3qATl3f69GmfsdPNOHfs2GHV5s6da9XWrVtn1QpfCD579mxrTojtE4FiXHfddVbNaaMAJ3fffbdV27BhQ5l7QsXw+eefu91CmThdPPqrX/3KZ/zggw9ac5wuuHVS+MJvtzYKQPkqnCFJatu2rV+P/em9WyTptddeC0hPKD8xMTE+4+HDh1tznP4d5bRRQGm3t27ZsqVVe//9961ahw4din2uZcuWWbWpU6eWqi8v4RMbAAAAAJ7HwgYAAACA57GwAQAAAOB5LGwAAAAAeB6bB7hk3759Vm3o0KFWzelO4g899FCxtdq1a1tzFi5caNWOHj1aVJtw0SuvvGLVwsLCrJrTpgBe3yigShXf/3MpfFdvlE3dunUD9lzt2rWzak45TUxM9BlfeeWV1pwaNWpYtQceeMCqFc6HZN/FOzU11ZqTm5tr1apVs38Mbt++3aqhYnG6uHvKlCl+PXbjxo1W7eGHH/YZZ2VllaovuKfw+ad+/fp+Pe7JJ5+0ag0bNrRqv/nNb3zGd911lzXn2muvtWp16tSxak6bGBSuvffee9acwhtZVUR8YgMAAADA81jYAAAAAPA8FjYAAAAAPI+FDQAAAADPY/OAEJKSkmLV0tPTrZrTReW9evXyGb/44ovWnKZNm1q1F154wap9++23RfaJ4OjTp4/PuH379tYcpwsGP/zww2C15JrCmwU4fd+7du0qp268o/AF9JLze/fWW29ZtXHjxpXqNZ3uzO60ecD58+d9xmfOnLHm7Nmzx6q98847Vm3btm1WrfCGGRkZGdacw4cPW7WaNWtatb1791o1eFuzZs18xh988EGpn+vrr7+2ak55g7fk5eX5jI8fP27NadCggVXbv3+/VXM67/rjyJEjVi07O9uqNWrUyKqdOHHCZ/zRRx+Vqgev4xMbAAAAAJ7HwgYAAACA57GwAQAAAOB5LGwAAAAAeB6bB4S43bt3W7VBgwZZtb59+/qM582bZ815/PHHrVqrVq2s2q233lqSFhEghS9idroL+3fffWfVFi9eHLSeAi08PNyqTZo0qdjHrV271qqNHTs2EC1VKMOHD7dq33zzjVXr2rVrwF7z4MGDVm3FihVW7csvv/QZb9myJWA9OBk2bJhVc7rw1+lCcFQ8zz77rM+48AYlJTFlypSytoMQlJmZ6TPu16+fNWfVqlVWrW7dulZt3759Vm3lypU+4/nz51tzTp48adUWLVpk1Zw2D3CaVxnxiQ0AAAAAz2NhAwAAAMDzWNgAAAAA8DyusfGgwr8HKknvvvuuz/jtt9+25lSrZv9xd+/e3ar17NnTZ7x+/foS9Yfgyc3NtWpHjx51oZPiOV1PM378eKs2ZswYq1b4RorTp0+35pw6daoM3VUeL730ktstuKLwTYsvpyw3akRocrq58W233Vaq5yp8XYQkpaWlleq54C2pqalWzek6vUBy+jdZjx49rJrTNWJcL3gRn9gAAAAA8DwWNgAAAAA8j4UNAAAAAM9jYQMAAADA89g8IMS1bdvWqg0cONCqdezY0WfstFGAkz179li1zz77zM/uUN4+/PBDt1u4rMIX7DptCjB48GCr5nRx7oABAwLWF1CUlJQUt1tAgH366adW7Wc/+1mxj3O6aezQoUMD0RLgl8I36pacNwowxlg1btB5EZ/YAAAAAPA8FjYAAAAAPI+FDQAAAADPY2EDAAAAwPPYPMAlv/jFL6xacnKyVevfv79Vi4uLK9VrXrhwwao53bXe6UI1BF9YWFiRY0nq16+fVRs5cmSwWrqsUaNGWbXnnnvOZxwdHW3Nef/9963akCFDAtcYgEqvXr16Vs2fn2tvvPGGVTt16lRAegL88de//tXtFjyPT2wAAAAAeB4LGwAAAACex8IGAAAAgOeVaGEzefJkdezYUZGRkWrYsKH69euntLQ0nznnzp1TUlKS6tWrpzp16mjAgAHKyMgIaNOovHr27En+4Jrp06dzDoSrOAfCTZwDEepKtHnAhg0blJSUpI4dO+r8+fMaN26cbrvtNu3Zs0e1a9eWdPGi4o8//lhLly5VdHS0kpOT1b9/f23atCko30Aocrq4//777/cZO20U0KxZs4D1sG3bNqv2wgsvWLVQvpO9k8cee0zdu3evkPkrfCdhpzsLO2Vr5syZVu2dd96xat9//73PuHPnztachx56yKq1a9fOql155ZVW7eDBgz5jp4sgnS7O9ZJNmzZxDvQwpw05rrrqKqvmdAf6UFGRz4GlMW/ePKtWpUrpfhnlb3/7W1nbqfA4BwZX79693W7B80q0sPnkk098xvPnz1fDhg21fft2de/eXVlZWfrDH/6gP/7xj7rlllskXTzpXH311dqyZYvjP6Ryc3OVm5tbMM7Ozi7N94FK4oEHHlBUVJSkwORPIoPw3/LlywvyJ3EORPkL9DmQ/KEkOAci1JXpGpusrCxJUt26dSVJ27dv148//qjExMSCOa1bt1Z8fLw2b97s+ByTJ09WdHR0wdGkSZOytIRKJBD5k8ggSo9zINxE/uA2MohQU+qFTX5+vp566indeOONuvbaayVJx44dU40aNRQTE+MzNzY2VseOHXN8nrFjxyorK6vgOHToUGlbQiUSqPxJZBClwzkQbiJ/cBsZRCgq9Q06k5KStHv3bm3cuLFMDYSHhys8PLxMz1FeYmNjrdo111xj1V5//XWr1rp164D1kZqaatWmTZvmM165cqU1pyLdeDNQ+ZO8lcGqVatateHDh1u1AQMGWLXCH++3atWq1H04/S76unXrfMYTJkwo9fN7QWU8B3qd03Vrpb0ew22VMX/t27e3aj/9ZOASp591eXl5PuPZs2dbc7jAvWQqYwaDrUWLFm634HmlOqMnJydr1apVWrdunc9FxHFxccrLy1NmZqbP/IyMDMeLnoHSIH9wGxmEm8gf3EYGEapKtLAxxig5OVkpKSlau3atmjdv7vP1Dh06qHr16lqzZk1BLS0tTQcPHlSXLl0C0zEqtdGjR5M/uIZzINzGORBu4hyIUFeiX0VLSkrSH//4R61cuVKRkZEFvy8ZHR2tmjVrKjo6Wo8++qiefvpp1a1bV1FRURoxYoS6dOly2R2pgJJYsmQJ+YNrnnnmGS1btowMwjWcA+EmzoEIdSVa2Lz55puSLt4g7KfmzZunoUOHSpJeffVVValSRQMGDFBubq569+7t+XtXIHRkZWWRP7jmD3/4gyTOgXAP50C4iXMgQl2Ycbqa0kXZ2dmKjo4u99e9tFXhJXPmzLHmOF24GMgLvZwuyJ4+fbpVc7rx4dmzZwPWRyjLysry2UM/GNzKYOGbXi5dutSa07FjR7+ey+lGhP78VS98E09JWrRokVUbOXKkX31UNBU5fxXN4sWLrdq9995r1ebOnWvVHn/88aD0FAjBzmAo56/wP6YlafXq1VbNaUOI/fv3+4xbtmwZsL4qE86BwXVpd7mf+t///V+r5rRBRuFrmI4fPx64xkKEP/nz5nYwAAAAAPATLGwAAAAAeB4LGwAAAACex8IGAAAAgOeVaFc0L0pISLBqY8aMsWqdOnXyGV9xxRUB7ePMmTM+45kzZ1pzXnzxRat2+vTpgPaB0HX48GGfcf/+/a05Thc1jx8/vlSv99prr1m1Szsf/tRXX31VqucHQo3TphoAECp2795t1dLT062a08ZVP//5z33GFXHzAH/wiQ0AAAAAz2NhAwAAAMDzWNgAAAAA8DwWNgAAAAA8r8JvHnDPPff4VfPHnj17rNqqVaus2vnz563a9OnTfcaZmZml6gGVx9GjR63apEmT/KoBld1f/vIXq3bvvfe60AkCZe/evVbtb3/7m1Xr1q1bebQDlAunjaXefvttq/bCCy/4jEeMGGHNcfp3bEXDJzYAAAAAPI+FDQAAAADPY2EDAAAAwPNY2AAAAADwvDBjjHG7iZ/Kzs5WdHS0220gRGVlZSkqKiqor0EGcTnkD24LdgbJH4rCObD8Ob3fS5YssWqJiYk+4+XLl1tzfvOb31i106dPl6G78uVP/vjEBgAAAIDnsbABAAAA4HksbAAAAAB4XoW/QScAAADgRdnZ2VZt0KBBVq3wDTqfeOIJa47TDb0r2k07+cQGAAAAgOexsAEAAADgeSxsAAAAAHgeCxsAAAAAnsfmAQAAAIBHOG0oMGLEiCLHlQWf2AAAAADwPBY2AAAAADyPhQ0AAAAAzwu5hY0xxu0WEMLKIx9kEJdD/uC2YOeD/KEonAPhJn+yEXILm5ycHLdbQAgrj3yQQVwO+YPbgp0P8oeicA6Em/zJRpgJsaVxfn6+jhw5osjISOXk5KhJkyY6dOiQoqKi3G6tRLKzsz3buxR6/RtjlJOTo8aNG6tKleCuxy9l0Bij+Pj4kHkPSirU/gxLKpT6J38lF0p/fqURav2XVwb5GRwaQq1/zoElF2p/hiUVSv2XJH8ht91zlSpVdOWVV0qSwsLCJElRUVGuv6ml5eXepdDqPzo6ulxe51IGL22nGErvQWnQf2CQv9Kh/8ApjwzyMzi0hFL/nANLh/4Dw9/8hdyvogEAAABASbGwAQAAAOB5Ib2wCQ8P18SJExUeHu52KyXm5d4l7/cfCF5/D+jf27z+/dO/93n5PfBy75L3+w8Er78H9O+OkNs8AAAAAABKKqQ/sQEAAAAAf7CwAQAAAOB5LGwAAAAAeB4LGwAAAACex8IGAAAAgOeF7MJm9uzZatasmSIiIpSQkKCtW7e63ZKjzz77TH379lXjxo0VFhamFStW+HzdGKMJEyaoUaNGqlmzphITE5Wenu5Os4VMnjxZHTt2VGRkpBo2bKh+/fopLS3NZ865c+eUlJSkevXqqU6dOhowYIAyMjJc6rh8kcHgI4OXR/6Cj/xdHvkLPvJXNDIYfBUxgyG5sFm8eLGefvppTZw4UTt27FC7du3Uu3dvfffdd263Zjl9+rTatWun2bNnO3596tSpmjlzpt566y2lpqaqdu3a6t27t86dO1fOndo2bNigpKQkbdmyRatXr9aPP/6o2267TadPny6YM2rUKH300UdaunSpNmzYoCNHjqh///4udl0+yGD5IIPOyF/5IH/OyF/5IH+XRwbLR4XMoAlBnTp1MklJSQXjCxcumMaNG5vJkye72FXxJJmUlJSCcX5+vomLizPTpk0rqGVmZprw8HDzpz/9yYUOi/bdd98ZSWbDhg3GmIu9Vq9e3SxdurRgzpdffmkkmc2bN7vVZrkgg+4ggxeRP3eQv4vInzvI37+QQXdUhAyG3Cc2eXl52r59uxITEwtqVapUUWJiojZv3uxiZyW3f/9+HTt2zOd7iY6OVkJCQkh+L1lZWZKkunXrSpK2b9+uH3/80af/1q1bKz4+PiT7DxQy6B4ySP7cRP7In5vI30Vk0D0VIYMht7A5ceKELly4oNjYWJ96bGysjh075lJXpXOpXy98L/n5+Xrqqad044036tprr5V0sf8aNWooJibGZ24o9h9IZNAdZPAi8ucO8ncR+XMH+fsXMuiOipLBam43gNCQlJSk3bt3a+PGjW63gkqKDMJN5A9uIn9wW0XJYMh9YlO/fn1VrVrV2nEhIyNDcXFxLnVVOpf6DfXvJTk5WatWrdK6det05ZVXFtTj4uKUl5enzMxMn/mh1n+gkcHyRwb/hfyVP/L3L+Sv/JE/X2Sw/FWkDIbcwqZGjRrq0KGD1qxZU1DLz8/XmjVr1KVLFxc7K7nmzZsrLi7O53vJzs5WampqSHwvxhglJycrJSVFa9euVfPmzX2+3qFDB1WvXt2n/7S0NB08eDAk+g8WMlh+yKCN/JUf8mcjf+WH/Dkjg+WnQmbQ1a0LLmPRokUmPDzczJ8/3+zZs8cMGzbMxMTEmGPHjrndmiUnJ8fs3LnT7Ny500gyr7zyitm5c6f55ptvjDHGTJkyxcTExJiVK1eav//97+buu+82zZs3N2fPnnW5c2OeeOIJEx0dbdavX2+OHj1acJw5c6Zgzr//+7+b+Ph4s3btWrNt2zbTpUsX06VLFxe7Lh9ksHyQQWfkr3yQP2fkr3yQv8sjg+WjImYwJBc2xhgza9YsEx8fb2rUqGE6depktmzZ4nZLjtatW2ckWcfDDz9sjLm41d9zzz1nYmNjTXh4uOnVq5dJS0tzt+n/59S3JDNv3ryCOWfPnjXDhw83P/vZz0ytWrXMPffcY44ePepe0+WIDAYfGbw88hd85O/yyF/wkb+ikcHgq4gZDDPGmMB89gMAAAAA7gi5a2wAAAAAoKRY2AAAAADwPBY2AAAAADyPhQ0AAAAAz2NhAwAAAMDzWNgAAAAA8DwWNgAAAAA8j4UNAAAAAM9jYQMAAADA81jYAAAAAPA8FjYAAAAAPO//AGtc9xxFMxmWAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Nxlr6rM6C1Hl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysGaFdzHDmid",
        "outputId": "b95c0b5b-3179-4465-ff1f-e7f226ea63db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0357 - accuracy: 0.9892\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0288 - accuracy: 0.9910\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0224 - accuracy: 0.9930\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0188 - accuracy: 0.9943\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0168 - accuracy: 0.9946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShjlH7PbFAHb",
        "outputId": "853fb0f5-2584-4b8d-b178-9521e6bc5103"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.9791\n",
            "Test accuracy: 0.9790999889373779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciton to create and evaluate model with different activation functions\n",
        "def evaluate_activation(activation_function):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "        tf.keras.layers.Dense(128, activation=activation_function),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(train_images, train_labels, epochs=5)\n",
        "    test_loss, test_acc =model.evaluate(test_images, test_labels)\n",
        "    print(f\"Test accuracy with {activation_function}: {test_acc}\")"
      ],
      "metadata": {
        "id": "-jwJEpvwMXw0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models with different activation functions\n",
        "for activation in ['sigmoid','tanh', 'relu']:\n",
        "    evaluate_activation(activation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lniX40WMRPwr",
        "outputId": "eba73f53-a2b6-45d1-b1bc-5dd77069f59e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3975 - accuracy: 0.8963\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1961 - accuracy: 0.9441\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1435 - accuracy: 0.9588\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1114 - accuracy: 0.9681\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0890 - accuracy: 0.9749\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9688\n",
            "Test accuracy with sigmoid: 0.9688000082969666\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2856 - accuracy: 0.9165\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1356 - accuracy: 0.9609\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0919 - accuracy: 0.9730\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0670 - accuracy: 0.9798\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0509 - accuracy: 0.9850\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9758\n",
            "Test accuracy with tanh: 0.9757999777793884\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2640 - accuracy: 0.9238\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1163 - accuracy: 0.9661\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0800 - accuracy: 0.9760\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0592 - accuracy: 0.9819\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0452 - accuracy: 0.9863\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0743 - accuracy: 0.9759\n",
            "Test accuracy with relu: 0.9758999943733215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for lr in [0.001, 0.01, 0.1]:\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Flatten(input_shape=(28,28)),\n",
        "        tf.keras.Dense(128, activation= 'relu'),\n",
        "        tf.keras.layers.Dense(10, activation= 'softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(train_images, train_labels, epochs=5, batch_size=32)\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "    print(f\"Test accuracy with learning rate {lr}:{test_acc}\")"
      ],
      "metadata": {
        "id": "WjMdBNyvZkcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load your dataset and preprocess it\n",
        "# For example, you can use the Fashion MNIST dataset as a placeholder\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Create a neural network model\n",
        "model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),  # Add dropout with a dropout rate of 0.5 (you can adjust this value)\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHJ0aSZubVUt",
        "outputId": "39899915-e0fc-4545-b4ca-4c07b0b5c77d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.6231 - accuracy: 0.7786\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4772 - accuracy: 0.8285\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4422 - accuracy: 0.8399\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4273 - accuracy: 0.8443\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4092 - accuracy: 0.8498\n",
            "313/313 - 1s - loss: 0.3875 - accuracy: 0.8599 - 555ms/epoch - 2ms/step\n",
            "\n",
            "Test accuracy: 0.8598999977111816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load your dataset and preprocess it\n",
        "# For example, you can use the Fashion MNIST dataset as a placeholder\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Create a neural network model with L2 regularization\n",
        "model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),  # L2 regularization with a strength of 0.01\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),   # L2 regularization with a strength of 0.01\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaLyD2iLcKMa",
        "outputId": "beadcf82-ec88-44d0-d023-e517d88f6f77"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.0274 - accuracy: 0.7874\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.7031 - accuracy: 0.8085\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6554 - accuracy: 0.8177\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6168 - accuracy: 0.8267\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5997 - accuracy: 0.8301\n",
            "313/313 - 1s - loss: 0.6147 - accuracy: 0.8237 - 599ms/epoch - 2ms/step\n",
            "\n",
            "Test accuracy: 0.8237000107765198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load your dataset and preprocess it\n",
        "# For example, you can use the Fashion MNIST dataset as a placeholder\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Create a baseline model (no regularization)\n",
        "baseline_model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the baseline model\n",
        "baseline_model.compile(optimizer='adam',\n",
        "                       loss='sparse_categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# Create a regularized model with L2 regularization\n",
        "l2_model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the L2 regularized model\n",
        "l2_model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "# Create a regularized model with dropout\n",
        "dropout_model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),  # Add dropout with a dropout rate of 0.5\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5),  # Add dropout with a dropout rate of 0.5\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the dropout regularized model\n",
        "dropout_model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Train the models\n",
        "baseline_history = baseline_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "l2_history = l2_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "dropout_history = dropout_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the models\n",
        "baseline_test_loss, baseline_test_acc = baseline_model.evaluate(x_test, y_test, verbose=2)\n",
        "l2_test_loss, l2_test_acc = l2_model.evaluate(x_test, y_test, verbose=2)\n",
        "dropout_test_loss, dropout_test_acc = dropout_model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "print(f'\\nBaseline Test accuracy: {baseline_test_acc}')\n",
        "print(f'L2 Regularized Test accuracy: {l2_test_acc}')\n",
        "print(f'Dropout Regularized Test accuracy: {dropout_test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO51KB-hdBNi",
        "outputId": "3f845a6f-e344-497c-ebdc-d3a77723f5a1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4939 - accuracy: 0.8257 - val_loss: 0.4139 - val_accuracy: 0.8500\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3700 - accuracy: 0.8646 - val_loss: 0.4248 - val_accuracy: 0.8479\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3334 - accuracy: 0.8773 - val_loss: 0.4052 - val_accuracy: 0.8488\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3098 - accuracy: 0.8860 - val_loss: 0.3511 - val_accuracy: 0.8707\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2928 - accuracy: 0.8903 - val_loss: 0.3436 - val_accuracy: 0.8755\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.0382 - accuracy: 0.7896 - val_loss: 0.7568 - val_accuracy: 0.7954\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.7098 - accuracy: 0.8118 - val_loss: 0.7318 - val_accuracy: 0.7943\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.6541 - accuracy: 0.8206 - val_loss: 0.6818 - val_accuracy: 0.8027\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.6218 - accuracy: 0.8270 - val_loss: 0.6193 - val_accuracy: 0.8228\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5985 - accuracy: 0.8319 - val_loss: 0.6248 - val_accuracy: 0.8203\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.7782 - accuracy: 0.7233 - val_loss: 0.4858 - val_accuracy: 0.8223\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.5608 - accuracy: 0.8018 - val_loss: 0.4401 - val_accuracy: 0.8445\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.5202 - accuracy: 0.8180 - val_loss: 0.4319 - val_accuracy: 0.8456\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4910 - accuracy: 0.8258 - val_loss: 0.4102 - val_accuracy: 0.8500\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4762 - accuracy: 0.8314 - val_loss: 0.4323 - val_accuracy: 0.8385\n",
            "313/313 - 0s - loss: 0.3436 - accuracy: 0.8755 - 456ms/epoch - 1ms/step\n",
            "313/313 - 0s - loss: 0.6248 - accuracy: 0.8203 - 472ms/epoch - 2ms/step\n",
            "313/313 - 0s - loss: 0.4323 - accuracy: 0.8385 - 459ms/epoch - 1ms/step\n",
            "\n",
            "Baseline Test accuracy: 0.8755000233650208\n",
            "L2 Regularized Test accuracy: 0.8202999830245972\n",
            "Dropout Regularized Test accuracy: 0.8385000228881836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "(x_test, y_true) = 1\n",
        "\n",
        "\n",
        "model = keras.models.load_model('your_model.h5')\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Convert probability predictions to class labels\n",
        "y_pred = tf.argmax(y_pred, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1-score using TensorFlow/Keras metrics\n",
        "precision = tf.keras.metrics.Precision()(y_true, y_pred)\n",
        "recall = tf.keras.metrics.Recall()(y_true, y_pred)\n",
        "f1_score = tf.keras.metrics.F1Score(num_classes=num_classes, average='weighted')(y_true, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f'Precision: {precision.numpy()}')\n",
        "print(f'Recall: {recall.numpy()}')\n",
        "print(f'F1-Score: {f1_score.numpy()}')\n",
        "\n",
        "# Generate a classification report using scikit-learn\n",
        "report = classification_report(y_true, y_pred)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "DzaeuphefZ9x",
        "outputId": "5a6b44ce-729e-46ef-e226-94b6149b245e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-51006079a0cd>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Load your trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to be between 0 and 1\n",
        "\n",
        "# CNN Model\n",
        "cnn_model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the CNN model\n",
        "cnn_model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Reshape input data for CNN (add channel dimension)\n",
        "x_train_cnn = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test_cnn = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Train the CNN model\n",
        "cnn_model.fit(x_train_cnn, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the CNN model\n",
        "cnn_test_loss, cnn_test_acc = cnn_model.evaluate(x_test_cnn, y_test, verbose=2)\n",
        "\n",
        "# Baseline Feedforward Neural Network Model\n",
        "baseline_model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the baseline model\n",
        "baseline_model.compile(optimizer='adam',\n",
        "                       loss='sparse_categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# Train the baseline model\n",
        "baseline_model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the baseline model\n",
        "baseline_test_loss, baseline_test_acc = baseline_model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "# Compare the performance of the models\n",
        "print(\"CNN Model Test Accuracy:\", cnn_test_acc)\n",
        "print(\"Baseline Model Test Accuracy:\", baseline_test_acc)\n",
        "\n",
        "# Generate a classification report for the CNN model\n",
        "cnn_predictions = cnn_model.predict(x_test_cnn)\n",
        "cnn_pred_labels = [tf.argmax(prediction).numpy() for prediction in cnn_predictions]\n",
        "cnn_report = classification_report(y_test, cnn_pred_labels)\n",
        "print(\"CNN Model Classification Report:\")\n",
        "print(cnn_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmzQXFF8iEse",
        "outputId": "07ef44a8-f34b-4458-ae34-2ddb6cef7c1a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 48s 25ms/step - loss: 0.1420 - accuracy: 0.9560\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0465 - accuracy: 0.9855\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0328 - accuracy: 0.9896\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0245 - accuracy: 0.9921\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0177 - accuracy: 0.9945\n",
            "313/313 - 2s - loss: 0.0275 - accuracy: 0.9914 - 2s/epoch - 7ms/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2570 - accuracy: 0.9265\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1146 - accuracy: 0.9662\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0809 - accuracy: 0.9761\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0601 - accuracy: 0.9814\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0463 - accuracy: 0.9860\n",
            "313/313 - 1s - loss: 0.0768 - accuracy: 0.9758 - 563ms/epoch - 2ms/step\n",
            "CNN Model Test Accuracy: 0.9914000034332275\n",
            "Baseline Model Test Accuracy: 0.9757999777793884\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "CNN Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       980\n",
            "           1       1.00      1.00      1.00      1135\n",
            "           2       1.00      0.99      0.99      1032\n",
            "           3       0.99      1.00      0.99      1010\n",
            "           4       0.99      0.99      0.99       982\n",
            "           5       0.99      0.98      0.99       892\n",
            "           6       1.00      0.99      0.99       958\n",
            "           7       0.99      0.99      0.99      1028\n",
            "           8       1.00      0.99      0.99       974\n",
            "           9       0.98      0.99      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}